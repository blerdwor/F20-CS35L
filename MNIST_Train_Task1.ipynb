{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blerdwor/F20-CS35L/blob/main/MNIST_Train_Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 2- ECE 188, Spring 2022 - Deadline: June 10th, 2022. Please upload a link to your Github on Gradescope.\n",
        "# Train a Deep Learning model on the MNIST dataset and evaluate it on a test set.\n",
        "\n",
        "The first part in this notebook will take you though the training of the [MNIST Dataset](http://yann.lecun.com/exdb/mnist/) which is a collection of handwritten digits. \n",
        "\n",
        "We will build a Deep Learning based system that can recognise handwritten digits using [Keras](https://keras.io/) and [Tensorflow](https://www.tensorflow.org/). \n",
        "\n",
        "Note that the entire project will be done on a Google Colab. A tutorial to some basic colab instructions can be found [here](https://colab.research.google.com/?utm_source=scs-index#scrollTo=GJBs_flRovLc). \n",
        "\n",
        "Note that all the code needed is provided until Task 1, **you will only have to write code after the task 1 header**"
      ],
      "metadata": {
        "id": "a-utSW-VUF2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Necessary Packages\n",
        "\n",
        "We import Keras and Tensorflow to train our network and numpy to work with our data. \n",
        "\n",
        "We also import matplotlib to view our images. "
      ],
      "metadata": {
        "id": "fgnHUBjoUTcy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aDvD8R1TbbOi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 8)\n",
        "mpl.rcParams['axes.grid'] = False\n"
      ],
      "metadata": {
        "id": "OdYVH66MUciD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Data\n",
        "\n",
        "We perform some data preprocessing. Feel free to skip over this and use the train and test data as x_train and x_test"
      ],
      "metadata": {
        "id": "yuFHL78kUez_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2iKGDDuDbhRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8ffc51-ae53-4fc5-a6b9-2b1c3418946e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a model in keras.\n",
        "\n",
        "\n",
        " We define a simple simple network with 2 hidden layers. One fully connected dense layer with 8 neurons and one flatten layer that flattens the model into 1D structure which is then fed into a softmax output.\n",
        "\n",
        "This is a barebones keras structure. In task 1 you will be tasked with improving this model. "
      ],
      "metadata": {
        "id": "tEDsgxIcuv0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Dense(8,activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb3ONTl8Odrq",
        "outputId": "a0e43901-6524-4652-f818-d32a9652383e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 28, 28, 8)         16        \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                62730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,746\n",
            "Trainable params: 62,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile and train the model \n",
        "\n",
        "We now train our model. Before we do that we need to set some parameters to train the model. Hence we define the loss and optimizer to be used as well as batch size. The number of epochs refers to the number of training iterations. "
      ],
      "metadata": {
        "id": "7qepS8u7VJXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cwCRnA2OgPY",
        "outputId": "46018ad3-4f60-4f13-ad2d-c6f72552a6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 4s 7ms/step - loss: 0.4359 - accuracy: 0.8823 - val_loss: 0.2521 - val_accuracy: 0.9263\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.2948 - accuracy: 0.9159 - val_loss: 0.2424 - val_accuracy: 0.9322\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2832 - accuracy: 0.9209 - val_loss: 0.2313 - val_accuracy: 0.9350\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2760 - accuracy: 0.9214 - val_loss: 0.2224 - val_accuracy: 0.9372\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2693 - accuracy: 0.9248 - val_loss: 0.2273 - val_accuracy: 0.9380\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2653 - accuracy: 0.9263 - val_loss: 0.2361 - val_accuracy: 0.9363\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2628 - accuracy: 0.9271 - val_loss: 0.2351 - val_accuracy: 0.9353\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2606 - accuracy: 0.9264 - val_loss: 0.2308 - val_accuracy: 0.9352\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2575 - accuracy: 0.9284 - val_loss: 0.2276 - val_accuracy: 0.9395\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2561 - accuracy: 0.9286 - val_loss: 0.2315 - val_accuracy: 0.9385\n",
            "Epoch 11/15\n",
            "301/422 [====================>.........] - ETA: 0s - loss: 0.2593 - accuracy: 0.9277"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model "
      ],
      "metadata": {
        "id": "2IscBu-nVLw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "metadata": {
        "id": "SCRqjgb_OiN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We achieve an accuracy on the test set of 92% but can we do better?"
      ],
      "metadata": {
        "id": "nSdY-BY5vKZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looking at a prediction.\n",
        "\n",
        "Lets look at the prediction for a particular image in our model. We will look at one corect and one incorrect prediction and see if we can improve on the incorrect prediction. "
      ],
      "metadata": {
        "id": "y9a6QtAJ4Xby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist_label(image_probs):\n",
        "\n",
        "  return np.argmax(image_probs), np.max(image_probs)"
      ],
      "metadata": {
        "id": "g3uyTJ6253Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_test)\n",
        "\n",
        "image = x_test[0].reshape(input_shape[0], input_shape[1])\n",
        "label = np.argmax(y_test[0])\n",
        "image_probs = preds[0]"
      ],
      "metadata": {
        "id": "sZP5HsZO5OyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(image*0.5 + 0.5)  # To change [-1, 1] to [0,1]\n",
        "image_class, class_confidence = get_mnist_label(image_probs)\n",
        "plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AdIoM5GX5ygg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the incorrect prediction index here\n",
        "incorrect_index = 0\n",
        "\n",
        "for i in range(preds.shape[0]):\n",
        "\n",
        "  if np.argmax(preds[i]) != np.argmax(y_test[i]):\n",
        "\n",
        "    incorrect_index = i\n",
        "\n",
        "image_incorrect = x_test[incorrect_index].reshape(input_shape[0], input_shape[1])"
      ],
      "metadata": {
        "id": "qmmsBM_E6DUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(image_incorrect*0.5 + 0.5)  # To change [-1, 1] to [0,1]\n",
        "image_class, class_confidence = get_mnist_label(preds[i])\n",
        "plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HKsiOalv7Bsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that a 3 has been predicted with high confidence as a 6 does this change with our improved model below?"
      ],
      "metadata": {
        "id": "VfSIJAF57dhy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # TASK 1: Improve the accuracy of the model \n",
        "\n",
        "Your goal in task one is to improve the accuracy of the model on the test set. "
      ],
      "metadata": {
        "id": "LifPv5WJvSMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For image recogniton tasks convolutional neural networks work better than most other type of architectures. Your goal is to push the test accuracy above 99% percent. \n",
        "\n",
        "The following steps will get you there. \n",
        "\n",
        "1. Convert the 1st hidden Dense layer to a conv layer with 32 filters, a filter size of 3x3 and with relu activation. (I've done this step)\n",
        "2. Add a Maxpooling layer of size 2x2. \n",
        "3. Add another Conv layer with 64 filters, with a filter size of 3x3 with relu activation. \n",
        "4. Add a Maxpooling layer of size 2x2. \n",
        "5. Add Dropout to the layer after the Flatten layer. "
      ],
      "metadata": {
        "id": "nq8pen8-wdsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "improved_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(rate=0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "improved_model.summary()\n"
      ],
      "metadata": {
        "id": "LeDUJgK2wb4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complile and train the improved model. "
      ],
      "metadata": {
        "id": "ffzFzyOZ0UG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "improved_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "improved_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "aPBhYQml1OuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Improved model. \n",
        "\n",
        "You should achieve a test accuracy of greater than 99%!\n",
        "\n",
        "If not the code will throw an assertion error. "
      ],
      "metadata": {
        "id": "7a7EZNcv1r9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = improved_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Improved Test loss:\", score[0])\n",
        "print(\"Improved Test accuracy:\", score[1])\n",
        "\n",
        "assert score[1] > 0.99"
      ],
      "metadata": {
        "id": "lYKx0TKH2P6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looking at a prediction.\n",
        "\n",
        "Lets look at the prediction for a particular image in our model. We will look at one corect and one incorrect prediction and see if we can improve on the incorrect prediction. \n",
        "\n",
        "Check the predictions on the improved model, do you see improvements on the incorrect sample. "
      ],
      "metadata": {
        "id": "aD885MO57xoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "improved_preds = improved_model.predict(x_test)\n",
        "\n",
        "image = x_test[0].reshape(input_shape[0], input_shape[1])\n",
        "label = np.argmax(y_test[0])\n"
      ],
      "metadata": {
        "id": "0ozaLxNg7xoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(image*0.5 + 0.5)  # To change [-1, 1] to [0,1]\n",
        "image_class, class_confidence = get_mnist_label(improved_preds[0])\n",
        "plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y0qsS5jY7xoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(image_incorrect*0.5 + 0.5)  # To change [-1, 1] to [0,1]\n",
        "image_class, class_confidence = get_mnist_label(improved_preds[i])\n",
        "plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dyj5CbQD7xoW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "MNIST_Train_Task1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}